# Detecting-dysmorphic-facial-signs-for-medical-diagnosis
In this project we developed several classifiers to detect dsymorphic facial signs for medical diagnosis. Our goal is to develop a robust classifier that can discern between twelve commonly occurring syndromes: 22q11, Angelman, Apert, CDL, Down, FragileX, Marfan, Progeria, Sotos, TreacherCollins, Turner, and Williams. Our project can be broken down into three methods: facial-keypoint based classifiers, OpenFace feature vector based classifiers, and a VGGFace transfer learning classifier. We will discuss each section below regarding setup, dependencies, and execution.

Please refer to our [website](https://sites.google.com/a/wisc.edu/detecting-dysmorphic-facial-signs-for-medical-diagnosis/) for a more in-depth explanation and context of our work.

Data for this project is not released publicly. Data would be stored in the `data` directory following the convention detailed in the directory [notes](./data/NOTES.md).

## Facial-Keypoint based Classifiers
The first approach to classification is on the key-point locations themselves as input. We used an existing Dlib ResNet facial keypoint detector. Dlib provides a pre-trained machine-learning, facial-keypoint detection model built on the ResNet architecture. In our project we are using a lightweight python wrapper/library around Dlib called face_recognition exclusively for the keypoint detection. We investigated three design points of this classification approach: face normalization, classifier, and use of PCA.

For face normalization we started with our absolute centroid with fixed first point distance. This means we took the centroid of the face patch as generated by Dlib as true face center then the algorithm normalized the first pointâ€™s distance from centroid to be one. All other points were scaled by the same normalization constant. Our second approach to face normalization was relative face centroid without scaling computed by finding the average x and y values for all points.

Regarding the classification algorithm itself, we found in literature prevalent use of SVMs as classifiers on facial keypoints. We also explored a 2-layer neural network for comparison. For the neural network we performed some hyperparameter tuning but purposely did not invest much time into this aspect in favor of broader exploration.

Lastly, we explored PCA to filter unnecessary feature key-points from the input feature vector. For the absolute-normalization approach we used 10 dimensions and for relative-normalization we used 15 based on the order of effect that each dimension had in explaining variance.

### Dependencies
Python dependencies. Install via `pip`.
- face_recognition
- numpy
- pandas
- scipy
- scikit-learn
- scikit-image
- matplotlib
- seaborn
- (Optional) PIL

### Code
The following Jupyter Notebooks address these approachs:

- [Keypoint-Cloud-Classifier---Absoluate-Normal-Distance](./Keypoint-Cloud-Classifier---Absoluate-Normal-Distance.ipynb)
- [Keypoint-Cloud-Classifier---Relative-Distance](./Keypoint-Cloud-Classifier---Relative-Distance.ipynb)



## OpenFace Feature Vector based Classifiers
OpenFace is a deep neural network designed to perform image recognition. The method they used is to first extract and align faces using Dlib then pass it through their network to generate a facial description. By running two (or more) images through this pipeline one can compare the resulting feature vectors for similarity. Similar vectors have a higher likelihood of being the same face.

For our classification problem, we will be leveraging the resulting feature vectors to instead classify syndromes. We did this by running all Training, Testing, and Validation datasets through the OpenFace pipeline capturing a set of features and labels. We then implemented SVM and 2-layer neural network classifiers. The neural network classifier can be though of as adding two additional layers to the OpenFace network while hold original weights constant. Thus making this a deep learning approach.

### Dependencies

OpenFace dependencies. Follow their [setup guide](https://cmusatyalab.github.io/openface/setup/)

Python dependencies. Install via `pip`.
- numpy
- pandas
- scipy
- scikit-learn
- seaborn

### Code
The following Jupyter Notebook makes use of the feature vector dataset extracted from our image dataset. Follow [OpenFace's tutorial](https://cmusatyalab.github.io/openface/demo-3-classifier/) up through the representation file generation. Copy these files into the `data` directory in this repo following the convention detailed in the directory [notes](./data/NOTES.md).

- [Openface-Feature-Models](OpenFace-Feature-Models.ipynb)


## VGGFace Transfer Learning Classifier
In the past few years, advancements in facial keypoints detection have been made by the application of deep convolutional neural networks (DCNN), which is a special type of feed-forward neural network with shared weights and local connectivity. The last approach to classification that we have investigated is to retrain an existing VGGFace (DCNN) model to perform classification. We used the ResNet-50 architecture (residual network) from keras-vggface library (an implementation of VGGFace pretrained on the VGGFace dataset). ResNet makes it possible to train up to hundreds or even thousands of layers and still achieves compelling performance. We used the feature extraction layers of the net (not the top three fully connected layers of the net) and added a fully connected layer as the last layer with activation softmax and used average pooling in the net. Cross entropy was used as the loss function and the model was trained for 200 epochs.

### Dependencies

Python dependencies. Install via `pip`.
- keras
- keras_vggface
- scikit-learn
- numpy
- matplotlib

### Code
The following python scripts were developed.
- [VGGFACE_Test](./VGGFACE_Test.py)
- [VGGFACE_Train](./VGGFACE_Train.py)



# Additional work not presented in writeup
- [Keypoint-Image-Classifier](./Keypoint-Image-Classifier.ipynb)
  - Attempt at a network trained from scratch.
  - This was / is not complete nor functional.

- [Keypoint-Patches-Classifier](./Keypoint-Patches-Classifier.ipynb)
  - Attempt to extract patches around each keypoint. A deep stack of keypoint patches as input into a network.
  - This does not work well. We opt not to discuss it.

- [Transfer-Learning-Approach-Confusion-Matrix](./Transfer-Learning-Approach-Confusion-Matrix.ipynb)
  - Simple script to generate a confusion matrix image.
