{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from skimage.transform import resize\n",
    "from skimage.util import pad\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "LABELS = ['22q11','Angelman','Apert','CDL','Down','FragileX','Marfan','Progeria','Sotos','TreacherCollins','Turner','Williams']\n",
    "IMAGE_PATCH_SIZE = 256\n",
    "EXTRA_PAD = 32\n",
    "\n",
    "#LABELS.remove('CDL')\n",
    "\n",
    "\n",
    "def load_dataset_patches(setPath):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for label in LABELS:\n",
    "            \n",
    "        directory = os.path.join(setPath,label)\n",
    "        for f in os.listdir(directory):\n",
    "            path = os.path.join(directory,f)\n",
    "            \n",
    "            if os.path.isfile(path) and f != 'desktop.ini':\n",
    "                \n",
    "                # Extract landmarks\n",
    "                image = face_recognition.load_image_file(path)\n",
    "                face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "                # Process faces\n",
    "                for landmarks in face_landmarks_list:\n",
    "                    \n",
    "                    # find dimensions\n",
    "                    top = image.shape[0]\n",
    "                    bottom = 0\n",
    "                    left = image.shape[1]\n",
    "                    right = 0\n",
    "                    \n",
    "                    for featureType in landmarks.keys():\n",
    "                        for point in landmarks[featureType]:\n",
    "                            (x,y) = point\n",
    "                            \n",
    "                            if x < left:\n",
    "                                left = x\n",
    "                            if x > right:\n",
    "                                right = x\n",
    "                            if y < top:\n",
    "                                top = y\n",
    "                            if y > bottom:\n",
    "                                bottom = y\n",
    "                                \n",
    "                    top = top - EXTRA_PAD if top - EXTRA_PAD >= 0 else 0\n",
    "                    bottom = bottom + EXTRA_PAD if bottom + EXTRA_PAD < image.shape[0] else image.shape[0] - 1\n",
    "                    left = left - EXTRA_PAD if left - EXTRA_PAD >= 0 else 0\n",
    "                    right = right + EXTRA_PAD if right + EXTRA_PAD < image.shape[1] else image.shape[1] - 1\n",
    "                    \n",
    "                    height = bottom - top\n",
    "                    width = right - left\n",
    "                    \n",
    "                    if height > width:\n",
    "                        # fix height\n",
    "                        diff = height - width\n",
    "                        bottom = bottom - diff\n",
    "                        \n",
    "                    elif height < width:\n",
    "                        # fix width\n",
    "                        diff = width - height\n",
    "                        right = right - diff\n",
    "                            \n",
    "                    \n",
    "                    # extract patch from image\n",
    "                    img_patch = image[top:bottom,left:right,:]\n",
    "                    img_patch_resized = resize(img_patch,(IMAGE_PATCH_SIZE,IMAGE_PATCH_SIZE,3))\n",
    "\n",
    "                    X.append(img_patch_resized)\n",
    "                    Y.append(label)\n",
    "                    \n",
    "    # pack into numpy structure\n",
    "    X_pack = np.zeros([len(X),IMAGE_PATCH_SIZE,IMAGE_PATCH_SIZE,3])\n",
    "    for i in range(0,len(X)):\n",
    "        X_pack[i,:,:] = X[i]\n",
    "    Y_pack = np.array(Y)\n",
    "    \n",
    "    return X_pack, Y_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312, 256, 256, 3)\n",
      "(312,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_dataset_patches('./data/raw/Test')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 256, 256, 3)\n",
      "(281,)\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = load_dataset_patches('./data/raw/Validate')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 256, 256, 3)\n",
      "(1023,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_dataset_patches('./data/raw/Train')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 12)\n",
      "(312, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "Y_train = encoder.fit_transform(y_train)\n",
    "Y_test = encoder.transform(y_test)\n",
    "Y_val = encoder.transform(y_val)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/curt/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 250, 250, 64)      9472      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 246, 246, 64)      102464    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 242, 242, 32)      51232     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 240, 240, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 238, 238, 32)      9248      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1812608)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                116006976 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 116,189,420\n",
      "Trainable params: 116,189,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (7,7), activation='relu', input_shape=(IMAGE_PATCH_SIZE,IMAGE_PATCH_SIZE,3)))\n",
    "model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(Conv2D(32, (5,5), activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/curt/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1023 samples, validate on 281 samples\n",
      "Epoch 1/15\n",
      "   8/1023 [..............................] - ETA: 31:01 - loss: 2.4556 - accuracy: 0.1250"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=8, epochs=15, shuffle=True, validation_data=(X_val,Y_val))\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, Y_train, batch_size=32, verbose=1)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Y_pred = model.predict(X_train)\n",
    "y_pred = encoder.inverse_transform(Y_pred)\n",
    "\n",
    "conf = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(conf, index = [i for i in LABELS],\n",
    "                  columns = [i for i in LABELS])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val, Y_val, batch_size=32, verbose=1)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = encoder.inverse_transform(Y_pred)\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(conf, index = [i for i in LABELS],\n",
    "                  columns = [i for i in LABELS])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "save_dir = './models'\n",
    "model_name = 'image-classifier-{}.h5'.format(int(time.time()))\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save_weights(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
