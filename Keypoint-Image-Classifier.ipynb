{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from skimage.transform import resize\n",
    "from skimage.util import pad\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "LABELS = ['22q11','Angelman','Apert','CDL','Down','FragileX','Marfan','Progeria','Sotos','TreacherCollins','Turner','Williams']\n",
    "IMAGE_PATCH_SIZE = 256\n",
    "EXTRA_PAD = 32\n",
    "\n",
    "#LABELS.remove('CDL')\n",
    "\n",
    "\n",
    "def load_dataset_patches(setPath):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for label in LABELS:\n",
    "            \n",
    "        directory = os.path.join(setPath,label)\n",
    "        for f in os.listdir(directory):\n",
    "            path = os.path.join(directory,f)\n",
    "            \n",
    "            if os.path.isfile(path) and f != 'desktop.ini':\n",
    "                \n",
    "                # Extract landmarks\n",
    "                image = face_recognition.load_image_file(path)\n",
    "                face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "                # Process faces\n",
    "                for landmarks in face_landmarks_list:\n",
    "                    \n",
    "                    # find dimensions\n",
    "                    top = image.shape[0]\n",
    "                    bottom = 0\n",
    "                    left = image.shape[1]\n",
    "                    right = 0\n",
    "                    \n",
    "                    for featureType in landmarks.keys():\n",
    "                        for point in landmarks[featureType]:\n",
    "                            (x,y) = point\n",
    "                            \n",
    "                            if x < left:\n",
    "                                left = x\n",
    "                            if x > right:\n",
    "                                right = x\n",
    "                            if y < top:\n",
    "                                top = y\n",
    "                            if y > bottom:\n",
    "                                bottom = y\n",
    "                                \n",
    "                    top = top - EXTRA_PAD if top - EXTRA_PAD >= 0 else 0\n",
    "                    bottom = bottom + EXTRA_PAD if bottom + EXTRA_PAD < image.shape[0] else image.shape[0] - 1\n",
    "                    left = left - EXTRA_PAD if left - EXTRA_PAD >= 0 else 0\n",
    "                    right = right + EXTRA_PAD if right + EXTRA_PAD < image.shape[1] else image.shape[1] - 1\n",
    "                    \n",
    "                    height = bottom - top\n",
    "                    width = right - left\n",
    "                    \n",
    "                    if height > width:\n",
    "                        # fix height\n",
    "                        diff = height - width\n",
    "                        bottom = bottom - diff\n",
    "                        \n",
    "                    elif height < width:\n",
    "                        # fix width\n",
    "                        diff = width - height\n",
    "                        right = right - diff\n",
    "                            \n",
    "                    \n",
    "                    # extract patch from image\n",
    "                    img_patch = image[top:bottom,left:right,:]\n",
    "                    img_patch_resized = resize(img_patch,(IMAGE_PATCH_SIZE,IMAGE_PATCH_SIZE,3))\n",
    "\n",
    "                    X.append(img_patch_resized)\n",
    "                    Y.append(label)\n",
    "                    \n",
    "    # pack into numpy structure\n",
    "    X_pack = np.zeros([len(X),IMAGE_PATCH_SIZE,IMAGE_PATCH_SIZE,3])\n",
    "    for i in range(0,len(X)):\n",
    "        X_pack[i,:,:] = X[i]\n",
    "    Y_pack = np.array(Y)\n",
    "    \n",
    "    return X_pack, Y_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312, 256, 256, 3)\n",
      "(312,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_dataset_patches('./data/raw/Test')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 256, 256, 3)\n",
      "(281,)\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = load_dataset_patches('./data/raw/Validate')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 256, 256, 3)\n",
      "(1023,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_dataset_patches('./data/raw/Train')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 12)\n",
      "(312, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "Y_train = encoder.fit_transform(y_train)\n",
    "Y_test = encoder.transform(y_test)\n",
    "Y_val = encoder.transform(y_val)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (7,7), activation='relu', input_shape=(IMAGE_PATCH_SIZE,IMAGE_PATCH_SIZE,3)))\n",
    "model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(Conv2D(32, (5,5), activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
